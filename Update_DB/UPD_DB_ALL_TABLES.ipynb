{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:paramiko.transport:Connected (version 2.0, client OpenSSH_8.9p1)\n",
            "INFO:paramiko.transport:Authentication (password) successful!\n",
            "INFO:root:Processing table: sales\n",
            "INFO:root:Processing table: ms_sales\n",
            "INFO:root:Processing table: ms_stock\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import logging\n",
        "import shutil\n",
        "from sqlalchemy import create_engine, text\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from sshtunnel import SSHTunnelForwarder\n",
        "\n",
        "\n",
        "import warnings\n",
        "\n",
        "\n",
        "DATA = {\n",
        "    \"sales\": {\n",
        "        \"FOLDER_PATH_IN\": 'C:\\\\Users\\\\dmandree\\\\Downloads\\\\TL_new',\n",
        "        \"FOLDER_PATH_OUT\": 'C:\\\\Users\\\\dmandree\\\\Downloads\\\\TL_arch',\n",
        "        \"SHEET\": 'TurnoverList',\n",
        "        \"COL_NAMES\": ['Day', 'Store', 'Company', 'Open', 'Amount', 'Curr', 'Pcs', 'Rcp', 'People', 'Hours', 'Work', 'Comp:', 'Open_1', 'Amount_1', 'Curr_1', 'Pcs_1', 'Rcp_1', 'People_1', 'Hours_1', 'Work_1'],\n",
        "        \"COMPANIES\": ['Guess Kazakhstan', 'Guess CIS'],\n",
        "        \"SKIP\": 0,\n",
        "        \"IF_EXISTS\": 'append'\n",
        "    },\n",
        "    \"ms_sales\": {\n",
        "        \"FOLDER_PATH_IN\": 'C:\\\\Users\\\\dmandree\\\\Downloads\\\\RTL_new',\n",
        "        \"FOLDER_PATH_OUT\": 'C:\\\\Users\\\\dmandree\\\\Downloads\\\\RTL_arch',\n",
        "        \"SHEET\": 'RTL50000_by_season_by_store old',\n",
        "        \"COL_NAMES\": ['Company', 'Country', 'Day', 'Mfg Season', 'Line Code', 'Gender', 'Dept Group', 'Dept', 'Sub Dept', 'Class', 'Class_1', 'Style', 'Style_1', 'Chain', 'Store', 'Store_1', 'Metrics', 'Ttl Sls Qty', 'TTL Curr Rtl Price €', 'Discount €', 'Ttl Sls €', 'Ttl Cost LC', 'Ttl Sls Trasp Cost LC', 'Ttl Cost €', 'Ttl Sls LC', 'Ttl Sls Trasp Cost €'],\n",
        "        \"COMPANIES\": ['RU', 'KZ'],\n",
        "        \"SKIP\": 3,\n",
        "        \"IF_EXISTS\": 'append'\n",
        "    },\n",
        "    \"ms_stock\": {\n",
        "        \"FOLDER_PATH_IN\": 'C:\\\\Users\\\\dmandree\\\\Downloads\\\\FNC_new',\n",
        "        \"FOLDER_PATH_OUT\": 'C:\\\\Users\\\\dmandree\\\\Downloads\\\\FNC_arch',\n",
        "        \"SHEET\": 'FNC03-50001-Margin_stock all st',\n",
        "        \"COL_NAMES\": ['Company', 'Day', 'Store', 'Store_1', 'Mfg Season', 'Line Code', 'Line_Code_1', 'Style', 'Style_1', 'Sub_Dept', 'Sub_Dept_1', 'Metrics', 'TTL EOH Ttl Qty', 'TTL Loading Cost €', 'TTL Loading Cost LC', 'TTL Trasp Cost €', 'Cost €'],\n",
        "        \"COMPANIES\": ['RU', 'KZ'],\n",
        "        \"SKIP\": 2,\n",
        "        \"IF_EXISTS\": 'replace'\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# Folder for Dict\n",
        "DICT_PATH = 'C:\\\\Users\\\\dmandree\\\\OneDrive - Guess Inc\\\\D Project\\\\Dict\\\\Mapping.xlsx'\n",
        "\n",
        "# Список страниц, которые мы трансформируем в датафреймы\n",
        "LIST_OF_SHEETS = [\"Stores\", \"Dist_managers\", \"VM\", \"Fin_Calendar_old\", \"Fin_Calendar_new\", \"Template\", \"Start_date\"]\n",
        "\n",
        "# DB and SSH cnnection parameters\n",
        "DB_PARAMS = {\n",
        "    'database': 'postgres',\n",
        "    'user': 'postgres',\n",
        "    'password': '1296',\n",
        "    'host': 'localhost'\n",
        "}\n",
        "\n",
        "SSH_TUNNEL_PARAMS = {\n",
        "    'ssh_address_or_host': ('79.174.86.163', 22),\n",
        "    'ssh_username': 'root',\n",
        "    'ssh_password': 'S0SJcmYwL0ZsmUId',\n",
        "    'remote_bind_address': ('127.0.0.1', 5432),\n",
        "    'local_bind_address': ('127.0.0.1', 8001)\n",
        "}\n",
        "\n",
        "# Logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Ignore all UserWarnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Function to read Excel files\n",
        "def read_excel_files(FOLDER_PATH_IN, FOLDER_PATH_OUT, SHEET, SKIP, COL_NAMES):\n",
        "    file_list = os.listdir(FOLDER_PATH_IN)\n",
        "    dfs = []\n",
        "    for file in file_list:\n",
        "        file_path = os.path.join(FOLDER_PATH_IN, file)\n",
        "        with pd.ExcelFile(file_path) as xls:\n",
        "            data = pd.read_excel(xls, sheet_name=SHEET, skiprows=SKIP, names=COL_NAMES)\n",
        "            dfs.append(data)\n",
        "        # Moving the file after processing\n",
        "        # move_processed_file(file_path, FOLDER_PATH_OUT, file)\n",
        "    \n",
        "    # Check if the list is not empty    \n",
        "    if dfs:\n",
        "        df = pd.concat(dfs, ignore_index=True)\n",
        "        return df\n",
        "    else:\n",
        "        print(\"No Excel files found or no data read from the files.\")\n",
        "        return None\n",
        "\n",
        "# Function to move file to archive folder\n",
        "def move_processed_file(file_path, FOLDER_PATH_OUT, file):\n",
        "    new_path = os.path.join(FOLDER_PATH_OUT, file)\n",
        "    if os.path.exists(new_path):\n",
        "        try:\n",
        "            os.remove(new_path)\n",
        "        except PermissionError:\n",
        "            print(\"The file is in use by another process and cannot be deleted.\")\n",
        "    try:\n",
        "        shutil.move(file_path, FOLDER_PATH_OUT)\n",
        "    except (IOError, shutil.Error) as e:\n",
        "        print(f\"Error while moving file '{file_path}': {e}\")\n",
        "\n",
        "# Function to create dict data\n",
        "def load_excel_sheets(DICT_PATH, LIST_OF_SHEETS):\n",
        "    return {sheet: pd.read_excel(DICT_PATH, sheet_name=sheet) for sheet in LIST_OF_SHEETS}\n",
        "\n",
        "# Function to process data\n",
        "def process_data(df, COMPANIES):\n",
        "    if df is None or df.empty:\n",
        "        return df\n",
        "    else:\n",
        "        if df['Day'].dtype == 'O':\n",
        "            df['Day'] = df['Day'].str[-10:].str.replace(',', '').str.replace(' ', '')\n",
        "        df[\"Day\"] = pd.to_datetime(df[\"Day\"]).dt.date\n",
        "        df = df.loc[df['Company'].isin(COMPANIES)]\n",
        "        df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "        return df\n",
        "\n",
        "# Function to filtering unique dates in a dataframe\n",
        "def create_outer_df(df):\n",
        "    unique_combinations = df['day'].unique()\n",
        "    outer_df = pd.DataFrame(unique_combinations, columns=['key'])\n",
        "    return outer_df\n",
        "\n",
        "# Function for creating an SSH tunnel\n",
        "def create_ssh_tunnel():\n",
        "    ssh_tunnel = SSHTunnelForwarder(**SSH_TUNNEL_PARAMS)\n",
        "    return ssh_tunnel\n",
        "\n",
        "# Function to connecting to a database\n",
        "def create_db_engine(ssh_tunnel):\n",
        "    DB_PARAMS['port'] = ssh_tunnel.local_bind_port\n",
        "    engine_str = f\"postgresql://{DB_PARAMS['user']}:{DB_PARAMS['password']}@{DB_PARAMS['host']}:{DB_PARAMS['port']}/{DB_PARAMS['database']}\"\n",
        "    engine = create_engine(engine_str)\n",
        "    return engine\n",
        "\n",
        "# Function to get date intersections\n",
        "def get_intersections(engine, df):\n",
        "    if df is None or df.empty:\n",
        "        intersection_df = []\n",
        "    else:\n",
        "        query = text('select DISTINCT day as key from sales')\n",
        "        inner_df = pd.read_sql(query, engine)['key']\n",
        "        inner_df = df['day'].unique()\n",
        "        intersection_df = pd.merge(create_outer_df(df), pd.DataFrame({'key': inner_df}), on='key', how='inner')['key'].tolist()\n",
        "        return intersection_df\n",
        "    \n",
        "# Function to remove intersections from the database\n",
        "def delete_intersections(session, intersection_df):\n",
        "    if intersection_df:\n",
        "        delete_query = text('DELETE FROM sales WHERE day = ANY(:keys)')\n",
        "        try:\n",
        "            session.execute(delete_query, {'keys': intersection_df})\n",
        "            session.commit()\n",
        "        except Exception as e:\n",
        "            print(f\"Error while deleting records: {e}\")\n",
        "\n",
        "# Function to load data to database\n",
        "def load_data_to_db(df, engine, name, IF_EXISTS):\n",
        "    try:\n",
        "        with engine.connect() as conn:\n",
        "            df.to_sql(name, conn, if_exists=IF_EXISTS, index=False)\n",
        "    except Exception as e:\n",
        "        print(f\"Error while loading data to the database: {e}\")\n",
        "\n",
        "# Function to transform and load dict data to database        \n",
        "def transform_and_load_dict(engine, dfs):\n",
        "    for df_name, df in dfs.items():\n",
        "        df.columns = df.columns.str.lower()\n",
        "        df.to_sql(df_name.lower(), engine, if_exists=\"replace\", index=False)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "        \n",
        "    # Create SSH tunnel\n",
        "    with create_ssh_tunnel() as ssh_tunnel:\n",
        "        \n",
        "        # Create database engine\n",
        "        engine = create_db_engine(ssh_tunnel)\n",
        "        \n",
        "        # Create session\n",
        "        Session = sessionmaker(bind=engine)\n",
        "    \n",
        "        with Session() as session:\n",
        "            # Iterate over dictionary items\n",
        "            for table_name, table_info in DATA.items():  \n",
        "                logging.info(f\"Processing table: {table_name}\")\n",
        "            \n",
        "                # Read Excel files\n",
        "                df = read_excel_files(\n",
        "                                    table_info[\"FOLDER_PATH_IN\"], \n",
        "                                    table_info[\"FOLDER_PATH_OUT\"], \n",
        "                                    table_info[\"SHEET\"], \n",
        "                                    table_info[\"SKIP\"], \n",
        "                                    table_info[\"COL_NAMES\"]\n",
        "                                    )\n",
        "\n",
        "                # Process data\n",
        "                df = process_data(df, table_info[\"COMPANIES\"])\n",
        "                                \n",
        "                # Create intersections\n",
        "                intersection_df = get_intersections(engine, df)\n",
        "                \n",
        "                # Remove intersections from the database\n",
        "                delete_intersections(session, intersection_df)\n",
        "                \n",
        "                # Load data to database\n",
        "                load_data_to_db(df, engine, table_name, table_info[\"IF_EXISTS\"])   \n",
        "                \n",
        "                # Create Dict \n",
        "                dfs = load_excel_sheets(DICT_PATH, LIST_OF_SHEETS)\n",
        "                \n",
        "                #transform and load dict data to database\n",
        "                transform_and_load_dict(engine, dfs)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
